{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from typing import List, Tuple, Callable, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(f, start=-1, end=1, steps=100, c=\"red\", l=\"NULL\"):\n",
    "    x = np.linspace(start, end, steps)\n",
    "    plt.plot(x, [f(_) for _ in x], label=l, color=c)\n",
    "    # plt.ylim([-1, 1])\n",
    "    # plt.legend()\n",
    "    # plt.plot(x, [f(_) for _ in x], 'ro',  markersize=2, color=c, )\n",
    "# plot(math.sqrt, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mY:N: ReLU(\u001b[33m[Y:N:pReLU=\u001b[92m+5.8975\u001b[0m\u001b[33m]\u001b[0m\u001b[35m) -> \u001b[33m[Y:N:ReLU=\u001b[92m+5.8975\u001b[0m\u001b[33m]\u001b[0m\u001b[0m\n",
      "\u001b[35mY:N: ReLU(\u001b[33m[Y:N:pReLU=\u001b[92m+4.8396\u001b[0m\u001b[33m]\u001b[0m\u001b[35m) -> \u001b[33m[Y:N:ReLU=\u001b[92m+4.8396\u001b[0m\u001b[33m]\u001b[0m\u001b[0m\n",
      "\u001b[35mY:N: ReLU(\u001b[33m[Y:N:pReLU=\u001b[92m+6.8396\u001b[0m\u001b[33m]\u001b[0m\u001b[35m) -> \u001b[33m[Y:N:ReLU=\u001b[92m+6.8396\u001b[0m\u001b[33m]\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "random.seed(34)\n",
    "\n",
    "\n",
    "STACK = []\n",
    "\n",
    "class Real():\n",
    "    def __init__(self, data):\n",
    "        self.data = data \n",
    "        self.ctx = None \n",
    "        self.id = None\n",
    "    @staticmethod\n",
    "    def uniform(i, j): return Real(random.uniform(i, j))\n",
    "    @staticmethod\n",
    "    def uniformn(n, i, j): return [Real.uniform(i, j) for _ in range(n)]\n",
    "\n",
    "    @staticmethod\n",
    "    def id(R:list, id:str):\n",
    "        for _ in range(len(R)): R[_].id = f\"{id}[{_}]\" \n",
    "\n",
    "    def __clr__(self, x:str): return f\"\\033[92m+{x}\\033[0m\" if self.data>0 else f\"\\033[91m{x}\\033[0m\"\n",
    "    def __id__(self): return f\"[{self.id}={self.__data__()}\\33[33m]\" if self.id!=None else f\"\\33[33m[{self.__data__()}\\33[33m]\" \n",
    "    def __data__(self): return self.__clr__(f\"{format(self.data,'.4f')}\")\n",
    "    def __str__(self): return f\"\\33[33m{self.__id__()}\\033[0m\"\n",
    "    def __repr__(self): return f\"\\33[33m{self.__id__()}\\033[0m\"\n",
    "\n",
    "\n",
    "    def add(x:tuple, y): y.data = x[0].data + x[1].data \n",
    "    def sub(x:tuple, y): y.data = x[0].data - x[1].data \n",
    "    def mul(x:tuple, y): y.data = x[0].data * x[1].data \n",
    "    def div(x:tuple, y): y.data = x[0].data / x[1].data \n",
    "\n",
    "    def __add__(a, b): return Function.new((a, b), Real.add, \"ADD\")\n",
    "    def __sub__(a, b): return Function.new((a, b), Real.add, \"SUB\")\n",
    "    def __mul__(a, b): return Function.new((a, b), Real.add, \"MUL\")\n",
    "    def __truediv__(a, b): return Function.new((a, b), Real.add, \"DIV\")\n",
    "\n",
    "    def relu(x:tuple, y): \n",
    "        if (x.data<=0): y.data = 0\n",
    "        else: y.data = x.data\n",
    "    def ReLU(z): return Function.new((z), Real.relu, \"ReLU\")\n",
    "    \n",
    "         \n",
    "    def _sum(x:tuple, y): y.data=sum([_.data for _ in x])\n",
    "    def _min(x:tuple, y): y.data=min([_.data for _ in x])\n",
    "    def _max(x:tuple, y): y.data=max([_.data for _ in x])\n",
    "\n",
    "    @staticmethod\n",
    "    def sum(x:list): return Function.new((x), Real._sum, \"SUM\") \n",
    "    @staticmethod\n",
    "    def min(x:list): return Function.new((x), Real._min, \"MIN\") \n",
    "    @staticmethod\n",
    "    def max(x:list): return Function.new((x), Real._max, \"MAX\") \n",
    "         \n",
    "\n",
    "class Function():\n",
    "    def __init__(self, x=None, fn=None, op=\"?\"):\n",
    "        self.fn = fn\n",
    "        self.op = op\n",
    "        self.x = x\n",
    "        self.y = self.ret() \n",
    "        STACK.append(self)\n",
    "    @staticmethod\n",
    "    def new(x:tuple, fn, op:str): return Function(x, fn, op).apply() \n",
    "    def ret(self): y=Real(0); y.ctx = self; return y; \n",
    "    def apply(self): \n",
    "        self.fn(self.x, self.y); \n",
    "        # print(self)\n",
    "        return self.y\n",
    "    def __str__(self): return f\"\\33[34m{self.op}\\033[0m {self.x} -> {self.y}\"  \n",
    "    def __repr__(self): return self.__str__()  \n",
    "\n",
    "class Neuron():\n",
    "    def __init__(self, id:str, x:list):\n",
    "        self.id = id; self.x = x; \n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.preact = None\n",
    "        self.activation = None\n",
    "        self.init(x)\n",
    "\n",
    "    def initWeights(self, x:list): self.w = Real.uniformn(len(x), -2, 2); Real.id(self.w, f\"{self.id}:w\")\n",
    "    def initBiases(self): self.b = Real.uniform(-2, 2); self.b.id = f\"{self.id}:b\"\n",
    "    def initPreAct(self): self.preact=Real.sum([w*x for w,x in zip(self.w,self.x)]) + self.b;self.preact.id=f\"{self.id}:pReLU\"\n",
    "    def initActivation(self): self.activation = self.preact.ReLU(); self.activation.id = f\"{self.id}:ReLU\"\n",
    "    def init(self,x:list): self.initWeights(x); self.initBiases(); self.initPreAct(); self.initActivation()\n",
    "\n",
    "    def prtweights(self): \n",
    "        for _ in self.w:print(_)\n",
    "    def prtinput(self): \n",
    "        for _ in self.x:print(_)\n",
    "    def __str__(self): return f\"\\33[35m{self.id}: ReLU({self.preact}\\33[35m) -> {self.activation}\\033[0m\"\n",
    "    def __repr__(self): return self.__str__()\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, id:str, x:list, n:int):\n",
    "        self.neurons = [Neuron(f\"{id}:N\", x) for _ in range(n)]\n",
    "        self.activitions = [_.activation for _ in self.neurons]\n",
    "    def __getitem__(self, i:int): return self.neurons[i]\n",
    "    def prtact(self):\n",
    "        for _ in self.activitions: print(_)\n",
    "            \n",
    "def compute():\n",
    "    for _ in STACK:\n",
    "        _.apply()\n",
    "\n",
    "x = Real.uniformn(1, 0, 2)\n",
    "Real.id(x, \"x\")\n",
    "L = Layer(\"H\", x, 1)\n",
    "y = Layer(\"Y\", L.activitions, 1)\n",
    "print(y[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97841f7eee096f6c1532918d4d0c14c99aa305bad21bd17c79ab4fdb68be0d34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
